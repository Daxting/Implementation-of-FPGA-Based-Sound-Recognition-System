{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a012bb1d-c2fd-4374-918c-7d2a2d11f2c3",
   "metadata": {},
   "source": [
    "連上wifi安裝必要的package(做一次就夠了)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef11004-3ce4-430c-9a3c-2b5536a38951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pynq.lib import Wifi\n",
    "# port = Wifi()\n",
    "# ssid = input(\"Type in the SSID:\")\n",
    "# pwd = input(\"Type in the password:\")\n",
    "# port.connect(ssid, pwd)\n",
    "#!ping 8.8.8.8\n",
    "!pip install --upgrade pip\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ae2681-b3b7-4db4-9bc2-e9bdadd4c922",
   "metadata": {},
   "source": [
    "import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9a57f09-78fb-404e-ae9e-d6257d07f910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import wave\n",
    "import math\n",
    "from numpy.fft import fft\n",
    "import sys\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, Dropout, Dense, GlobalAveragePooling2D, Concatenate, AveragePooling2D\n",
    "from keras.layers import Activation, BatchNormalization, add, Reshape, ReLU, DepthwiseConv2D, MaxPooling2D, Lambda\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import scipy.io as scio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d82a78-e7e7-46d3-b1cf-c7e5b532bfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定音訊 Overlay\n",
    "import numpy as np\n",
    "from pynq.overlays.base import BaseOverlay\n",
    "base = BaseOverlay(\"base.bit\")\n",
    "pAudio = base.audio\n",
    "pAudio.select_line_in()\n",
    "\n",
    "# 設定取樣率, 錄音時長\n",
    "sample_rate = 48000\n",
    "seconds = 0.02133\n",
    "num_channels = 2\n",
    "\n",
    "# 計算取樣幀數\n",
    "num_frames = sample_rate * seconds \n",
    "print(num_frames)\n",
    "pAudio.sample_len = sample_rate * seconds * num_channels\n",
    "print(\"start test record\")\n",
    "pAudio.record(seconds)\n",
    "print(\"end test record\")\n",
    "buf = pAudio.buffer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3957ff-f51a-41c6-afa3-46e01d848960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定取樣率和frame大小、frame shift\n",
    "sample_rate = 48000  # 取樣率\n",
    "frame_size = 0.02133    # 第一次錄製的frame大小（秒）\n",
    "frame_shift = 0.01    # 從第二次錄製開始的frame shift（秒）\n",
    "\n",
    "# 計算frame大小和frame shift對應的取樣數\n",
    "frame_size_samples = int(sample_rate * frame_size)\n",
    "frame_shift_samples = int(sample_rate * frame_shift)\n",
    "print(\"frame_size_samples:\", frame_size_samples)\n",
    "print(\"frame_shift_samples:\", frame_shift_samples)\n",
    "\n",
    "# 第一次錄製 (0.032s)\n",
    "pAudio.record(frame_size)\n",
    "# 工作區 buffer\n",
    "data_buf = np.frombuffer(pAudio.buffer, dtype=np.int8)\n",
    "\n",
    "\n",
    "# 處理第一次錄製的音訊數據\n",
    "print(\"Processed first recording of size:\", len(data_buf))\n",
    "\n",
    "# 從第二次錄製開始\n",
    "for i in range(100):\n",
    "    \n",
    "    # 錄製新的音訊數據\n",
    "    pAudio.record(frame_shift)\n",
    "    new_data = pAudio.buffer\n",
    "    \n",
    "    # 擦除緩衝區最前段 new_data 長度的資料\n",
    "    data_buf = data_buf[len(new_data):] \n",
    "    print(\"data_buf before:\", len(data_buf))\n",
    "\n",
    "    # 將 new_data 插入到緩衝區的末尾\n",
    "    data_buf = np.concatenate((data_buf, new_data), axis=None)\n",
    "    print(\"data_buf after:\", len(data_buf))\n",
    "    \n",
    "    # 處理音訊數據\n",
    "    # 取樣寬度(int32)\n",
    "    sample_width = 32\n",
    "\n",
    "    #資料型態處理\n",
    "    raw_bytes = np.frombuffer(data_buf, dtype=np.int8)\n",
    "    temp_buffer[:,:,:sample_width] = raw_bytes.reshape(-1, num_channels, sample_width)\n",
    "    print(frames.shape)\n",
    "    frames = np.left_shift(frames,8)/(256)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    #丟棄其中一個聲道的資料\n",
    "    frames_mono = frames[:, 1:, :]\n",
    "    frames_mono_int32 = frames_mono.astype(np.int32).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b1d72c-c7cb-4d06-9c1e-b039280e1335",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(temp_buffer.shape)\n",
    "print(frames.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a37115e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audioProcessingForBaseOverlay(input_signal, delay = 0, index = 0, maxindex = 167):\n",
    "\n",
    "    wlen=1024\n",
    "    inc=128\n",
    "    wave_data = input_signal\n",
    "    wave_data = wave_data/(np.max(input_signal))\n",
    "    framerate = 48000\n",
    "    fixed_signal = np.zeros(len(wave_data))\n",
    "    if delay != 0:\n",
    "        zeros=np.zeros(((wlen*delay),)) #在訊號前加0增加訓練集\n",
    "        #zeros=np.full(wlen*delay, 0.0001)\n",
    "        fixed_signal=np.concatenate((zeros,wave_data)) #填補後的信號記爲fixed_signal\n",
    "    else:\n",
    "        fixed_signal = wave_data\n",
    "    #print(wave_data.dtype)\n",
    "    signal_length=len(fixed_signal) #信號總長度\n",
    "    if signal_length<=wlen: #若信號長度小於一個幀的長度，則幀數定義爲1\n",
    "        nf=1\n",
    "    else: #否則，計算幀的總長度\n",
    "        nf=int(np.ceil((1.0*signal_length-wlen+inc)/inc))\n",
    "    pad_length=int((nf-1)*inc+wlen) #所有幀加起來總的鋪平後的長度\n",
    "    zeros=np.zeros((pad_length-signal_length,)) #不夠的長度使用0填補，類似於FFT中的擴充數組操作\n",
    "    pad_signal=np.concatenate((fixed_signal,zeros)) #填補後的信號記爲pad_signal\n",
    "    indices=np.tile(np.arange(0,wlen),(nf,1))+np.tile(np.arange(0,nf*inc,inc),(wlen,1)).T  #相當於對所有幀的時間點進行抽取，得到nf*nw長度的矩陣\n",
    "    #print(indices[:2])\n",
    "    indices=np.array(indices,dtype=np.int32) #將indices轉化爲矩陣\n",
    "    frames=pad_signal[indices] #得到幀信號\n",
    "\n",
    "    b = np.zeros((frames.shape[0], frames.shape[1]))\n",
    "    for i in range(0, frames.shape[0]):\n",
    "        windown=np.hamming(wlen)  #調用漢明窗\n",
    "        a=frames[i:i+1]\n",
    "        b[i]=a[0]*windown\n",
    "\n",
    "\n",
    "    # def PreEmphasised(x):\n",
    "    #     PointNumbers = len(x)\n",
    "    #     PreEmphasis = x\n",
    "    #     PointNumbers = int(PointNumbers)\n",
    "    #     for i in range (1, PointNumbers):\n",
    "    #         PreEmphasis[i] = PreEmphasis[i] - 0.97*PreEmphasis[i - 1]\n",
    "    #     return(PreEmphasis)\n",
    "\n",
    "    # y = np.zeros((b.shape[0], b.shape[1]))\n",
    "    # for i in range(0, b.shape[0]):\n",
    "    #     y[i] = PreEmphasised(b[i])\n",
    "\n",
    "    #FFT\n",
    "\n",
    "    Xtest = fft(b[0])\n",
    "    X = np.zeros((b.shape[0], len(Xtest)),dtype=np.complex_)\n",
    "\n",
    "    for i in range(0, b.shape[0]):\n",
    "        X[i] = fft(b[i])\n",
    "        N = len(X[0])\n",
    "        n = np.arange(N)\n",
    "        T = N/framerate\n",
    "        freq = n/T \n",
    "\n",
    "    n_oneside = N//2\n",
    "\n",
    "    # 取頻率點\n",
    "    freq20000 = 0\n",
    "    for i in range(n_oneside):\n",
    "        if(freq[i] > 20000):\n",
    "            freq20000 = i - 1\n",
    "            break\n",
    "    # get the one side frequency\n",
    "    #f_oneside = freq[:n_oneside]\n",
    "    f_oneside = freq[:freq20000]\n",
    "\n",
    "\n",
    "    X_oneside = np.zeros((X.shape[0], f_oneside.shape[0]),dtype=np.complex_)\n",
    "    for i in range (0, X.shape[0]):\n",
    "        #X_oneside[i] =X[i][:n_oneside]/n_oneside\n",
    "        X_oneside[i] =X[i][:freq20000]/freq20000\n",
    "\n",
    "\n",
    "    \n",
    "    square_X = np.zeros((X_oneside.shape[0], X_oneside.shape[1]))\n",
    "    square_X = np.square(np.abs(X_oneside))\n",
    "    #頻率點數量\n",
    "    #fp = n_oneside\n",
    "    fp = freq20000\n",
    "    #設計濾波器的最低頻率\n",
    "    fl = freq[0]\n",
    "    #設計濾波器的最高頻率\n",
    "    fh = freq[fp]\n",
    "    #print(f'maximum freq: {fh}')\n",
    "    #最低頻率對應的mel頻率\n",
    "    melfl = 2595.0 * np.log10(1 + fl/700.0)\n",
    "    #最高頻率對應的mel頻率\n",
    "    melfh = 2595.0 * np.log10(1 + fh/700.0)\n",
    "    # melfl 到 melfh 之間的濾波器個數\n",
    "    p = 64\n",
    "    #間隔點頻率(包括最低頻點及最高頻點)\n",
    "    MelF = np.linspace(melfl, melfh, p+2)\n",
    "    #將mel頻率轉回實際頻率\n",
    "    F = 700.0 * (10 ** (MelF/2595.0) - 1)\n",
    "    bank = np.zeros((p, fp))\n",
    "\n",
    "\n",
    "    for m in range(1, p+1):\n",
    "        F_left = F[m - 1]\n",
    "        F_mid = F[m]\n",
    "        F_right = F[m + 1]\n",
    "        for k in range(0, fp):\n",
    "            \n",
    "            if f_oneside[k] >= F_left and f_oneside[k] <= F_mid:\n",
    "                bank[m - 1][k] = (f_oneside[k] - F_left)/(F_mid - F_left)\n",
    "            elif f_oneside[k] > F_mid and f_oneside[k] <= F_right:\n",
    "                bank[m - 1][k] = (F_right - f_oneside[k])/(F_right - F_mid)        \n",
    "                \n",
    "\n",
    "    mel_X = np.matmul(square_X, np.transpose(bank))\n",
    "\n",
    "    min_positive_float = 0.0005\n",
    "    for i in range(mel_X.shape[0]):\n",
    "        for j in range(mel_X.shape[1]):\n",
    "            if mel_X[i][j] == 0.0005:\n",
    "                mel_X[i][j] = min_positive_float\n",
    "\n",
    "    log_X = 10* np.log10(mel_X)\n",
    "    return log_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ff4c2c",
   "metadata": {},
   "source": [
    "### 電腦端辨識測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb31b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import wave\n",
    "\n",
    "def list_devices():\n",
    "    \"\"\"列出所有可用的音頻裝置\"\"\"\n",
    "    devices = sd.query_devices()\n",
    "    for index, device in enumerate(devices):\n",
    "        print(f\"{index}: {device['name']} ({device['hostapi']})\", flush=True)\n",
    "\n",
    "def record_audio(duration, device_index, fs=44100):\n",
    "    \"\"\"使用指定的音頻裝置錄音\"\"\"\n",
    "    print(\"開始錄音...\")\n",
    "    recording = sd.rec(int(duration * fs), samplerate=fs, channels=2, dtype='int16', device=device_index)\n",
    "    sd.wait()  # 等待錄音結束\n",
    "    print(\"錄音結束。\")\n",
    "    return recording\n",
    "\n",
    "def save_wav(file_name, data, fs):\n",
    "    \"\"\"將 numpy 數據陣列保存為 WAV 檔案。\"\"\"\n",
    "    with wave.open(file_name, 'w') as wf:\n",
    "        wf.setnchannels(2)\n",
    "        wf.setsampwidth(2)\n",
    "        wf.setframerate(fs)\n",
    "        wf.writeframes(data.tobytes())\n",
    "\n",
    "list_devices()  # 列出所有音頻裝置\n",
    "while True:\n",
    "    try:\n",
    "        device_index = int(input(\"請輸入要使用的麥克風裝置ID: \"))\n",
    "        sd.check_input_settings(device=device_index)  # 檢查裝置ID是否有效\n",
    "        break\n",
    "    except ValueError:\n",
    "        print(\"輸入無效。請輸入一個有效的數字ID。\")\n",
    "    except Exception as e:\n",
    "        print(f\"錯誤: {e}. 請再次嘗試。\")\n",
    "\n",
    "duration = 10  # 總錄音時間為 10 秒\n",
    "fs = 44100  # 採樣率\n",
    "\n",
    "recording = record_audio(duration, device_index, fs)\n",
    "\n",
    "# # 將錄音分成兩段，每段 5 秒\n",
    "# first_part = recording[:int(5 * fs)]\n",
    "# second_part = recording[int(5 * fs):int(10 * fs)]\n",
    "\n",
    "# # 儲存兩個段落為 WAV 檔案\n",
    "# save_wav('first_part.wav', first_part, fs)\n",
    "# save_wav('second_part.wav', second_part, fs)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import wave\n",
    "import math\n",
    "from numpy.fft import fft\n",
    "import sys\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, Dropout, Dense, GlobalAveragePooling2D, Concatenate, AveragePooling2D\n",
    "from keras.layers import Activation, BatchNormalization, add, Reshape, ReLU, DepthwiseConv2D, MaxPooling2D, Lambda\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import scipy.io as scio\n",
    "\n",
    "def audioProcessingForBaseOverlay(input_signal, index = 0):\n",
    "\n",
    "    wlen=1024\n",
    "    inc=128\n",
    "    wave_data = input_signal\n",
    "    wave_data = wave_data/(np.max(abs(input_signal)))\n",
    "    framerate = 44100\n",
    "    fixed_signal = np.zeros(len(wave_data))\n",
    "    fixed_signal = wave_data\n",
    "    #print(wave_data.dtype)\n",
    "    signal_length=len(fixed_signal) #信號總長度\n",
    "    if signal_length<=wlen: #若信號長度小於一個幀的長度，則幀數定義爲1\n",
    "        nf=1\n",
    "    else: #否則，計算幀的總長度\n",
    "        nf=int(np.ceil((1.0*signal_length-wlen+inc)/inc))\n",
    "    pad_length=int((nf-1)*inc+wlen) #所有幀加起來總的鋪平後的長度\n",
    "    zeros=np.zeros((pad_length-signal_length,)) #不夠的長度使用0填補，類似於FFT中的擴充數組操作\n",
    "    pad_signal=np.concatenate((fixed_signal,zeros)) #填補後的信號記爲pad_signal\n",
    "    indices=np.tile(np.arange(0,wlen),(nf,1))+np.tile(np.arange(0,nf*inc,inc),(wlen,1)).T  #相當於對所有幀的時間點進行抽取，得到nf*nw長度的矩陣\n",
    "    #print(indices[:2])\n",
    "    indices=np.array(indices,dtype=np.int32) #將indices轉化爲矩陣\n",
    "    frames=pad_signal[indices] #得到幀信號\n",
    "\n",
    "    b = np.zeros((frames.shape[0], frames.shape[1]))\n",
    "    for i in range(0, frames.shape[0]):\n",
    "        windown=np.hamming(wlen)  #調用漢明窗\n",
    "        a=frames[i:i+1]\n",
    "        b[i]=a[0]*windown\n",
    "\n",
    "\n",
    "    # def PreEmphasised(x):\n",
    "    #     PointNumbers = len(x)\n",
    "    #     PreEmphasis = x\n",
    "    #     PointNumbers = int(PointNumbers)\n",
    "    #     for i in range (1, PointNumbers):\n",
    "    #         PreEmphasis[i] = PreEmphasis[i] - 0.97*PreEmphasis[i - 1]\n",
    "    #     return(PreEmphasis)\n",
    "    \n",
    "\n",
    "    # y = np.zeros((b.shape[0], b.shape[1]))\n",
    "    # for i in range(0, b.shape[0]):\n",
    "    #     y[i] = PreEmphasised(b[i])\n",
    "\n",
    "    #FFT\n",
    "\n",
    "    Xtest = fft(b[0])\n",
    "    X = np.zeros((b.shape[0], len(Xtest)),dtype=np.complex_)\n",
    "\n",
    "    for i in range(0, b.shape[0]):\n",
    "        X[i] = fft(b[i])\n",
    "        N = len(X[0])\n",
    "        n = np.arange(N)\n",
    "        T = N/framerate\n",
    "        freq = n/T \n",
    "\n",
    "    n_oneside = N//2\n",
    "\n",
    "\n",
    "\n",
    "    # get the one side frequency\n",
    "    f_oneside = freq[:n_oneside]\n",
    "\n",
    "\n",
    "    X_oneside = np.zeros((X.shape[0], f_oneside.shape[0]),dtype=np.complex_)\n",
    "    for i in range (0, X.shape[0]):\n",
    "        X_oneside[i] =X[i][:n_oneside]/n_oneside\n",
    "\n",
    "\n",
    "    \n",
    "    square_X = np.zeros((X_oneside.shape[0], X_oneside.shape[1]))\n",
    "    square_X = np.square(np.abs(X_oneside))\n",
    "\n",
    "    #頻率點數量\n",
    "    fp = n_oneside\n",
    "    #設計濾波器的最低頻率\n",
    "    fl = freq[0]\n",
    "    #設計濾波器的最高頻率\n",
    "    fh = freq[fp]\n",
    "    #print(f'maximum freq: {fh}')\n",
    "    #最低頻率對應的mel頻率\n",
    "    melfl = 2595.0 * np.log10(1 + fl/700.0)\n",
    "    #最高頻率對應的mel頻率\n",
    "    melfh = 2595.0 * np.log10(1 + fh/700.0)\n",
    "    # melfl 到 melfh 之間的濾波器個數\n",
    "    p = 64\n",
    "    #間隔點頻率(包括最低頻點及最高頻點)\n",
    "    MelF = np.linspace(melfl, melfh, p+2)\n",
    "    #將mel頻率轉回實際頻率\n",
    "    F = 700.0 * (10 ** (MelF/2595.0) - 1)\n",
    "    bank = np.zeros((p, fp))\n",
    "\n",
    "\n",
    "    for m in range(1, p+1):\n",
    "        F_left = F[m - 1]\n",
    "        F_mid = F[m]\n",
    "        F_right = F[m + 1]\n",
    "        for k in range(0, fp):\n",
    "            \n",
    "            if f_oneside[k] >= F_left and f_oneside[k] <= F_mid:\n",
    "                bank[m - 1][k] = (f_oneside[k] - F_left)/(F_mid - F_left)\n",
    "            elif f_oneside[k] > F_mid and f_oneside[k] <= F_right:\n",
    "                bank[m - 1][k] = (F_right - f_oneside[k])/(F_right - F_mid)        \n",
    "\n",
    "    mel_X = np.matmul(square_X, np.transpose(bank))\n",
    "\n",
    "    min_positive_float = 10**-7\n",
    "    for i in range(mel_X.shape[0]):\n",
    "        for j in range(mel_X.shape[1]):\n",
    "            if mel_X[i][j] < 10**-7:\n",
    "                mel_X[i][j] = min_positive_float\n",
    "\n",
    "    log_X = np.log10(mel_X)\n",
    "    return log_X\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "# 將錄製的音訊資料轉換為numpy array\n",
    "data_buf = np.squeeze(recording) # this is the result nparray\n",
    "#print(data_buf)\n",
    "# 畫出波形\n",
    "for channel_index in range(1):\n",
    "    plt.figure(num=None, figsize=(15, 3))\n",
    "    plt.title('Audio in Time Domain (Channel {})'.format(channel_index))\n",
    "    plt.xlabel('Time in s')\n",
    "    plt.ylabel('Amplitude')\n",
    "    time_axis = np.linspace(0, 10, 441000)\n",
    "    plt.plot(time_axis, data_buf)\n",
    "    plt.show()\n",
    "\n",
    "# Loads the model\n",
    "new_model = tf.keras.models.load_model('shuffleNet_v1_0603.h5')\n",
    "input_signal = np.frombuffer(b''.join(data_buf), dtype = np.short) #np.full(1024, -1) #測試用\n",
    "test_signal = np.zeros((1, 64, 64, 1)) #實際feature map\n",
    "temp_signal = np.zeros((1, 64)) #每一個音窗\n",
    "temp_signal = audioProcessingForBaseOverlay(input_signal) #input_signal 輸入訊號\n",
    "temp_signal = np.delete(temp_signal, 0, axis=0)\n",
    "num_matrices = temp_signal.shape[0] // 64\n",
    "# 使用 numpy.reshape 將原始陣列轉換為三維矩陣\n",
    "test_signal = np.append(test_signal, temp_signal[:num_matrices * 64, :].reshape((num_matrices, 64, 64, 1)), axis = 0)\n",
    "test_signal = np.delete(test_signal, 0, axis=0)\n",
    "print(f'done signal pre-emphasis')\n",
    "\n",
    "for i in range(test_signal.shape[0]):\n",
    "\n",
    "    test_signal1 = test_signal[i].reshape(1, 64, 64, 1)\n",
    "    # Re-evaluate the model\n",
    "    predictions = new_model.predict(test_signal1)\n",
    "    #print(len(predictions[0]))\n",
    "    print(predictions)\n",
    "    #輸出辨識結果\n",
    "    if predictions[0][1] > predictions[0][0]:\n",
    "        print('it is a car crashing signal!!!')\n",
    "    else:\n",
    "        print('it is not a car crashing signal???')\n",
    "print('finish')\n",
    "tf.keras.backend.clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
